{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a00cdc5-786c-4398-88e8-81269b03087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136d4aab-afb9-4d8f-8248-1a48a60121d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to RedBus\n",
    "driver.get(\"https://www.redbus.in/\")\n",
    "time.sleep(5)# wait for some 5 sec\n",
    "\n",
    "#RTCBuses\n",
    "View_rtc = driver.find_element(By.XPATH, '//a[@href=\"https://www.redbus.in/online-booking/rtc-directory\"]')\n",
    "View_rtc.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b072f292-ff8f-4a7a-b84a-e6a56f574e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Andra\n",
    "apsrtc_route_names = []\n",
    "apsrtc_route_links = []\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 20)\n",
    "driver.get('https://www.redbus.in/online-booking/rtc-directory')\n",
    "\n",
    "Andra = driver.find_element(By.XPATH, '//a[@href=\"/online-booking/apsrtc\"]')\n",
    "Andra.click()\n",
    "\n",
    "def scrape_data():\n",
    "    route_names = driver.find_elements(By.CLASS_NAME, \"route\")\n",
    "    for route_name in route_names:\n",
    "        apsrtc_route_names.append(route_name.text)\n",
    "\n",
    "    route_links = driver.find_elements(By.CLASS_NAME, \"route\")\n",
    "    hrefs = [route_link.get_attribute('href') for route_link in route_links]\n",
    "    for href in hrefs:\n",
    "        apsrtc_route_links.append(href)\n",
    "\n",
    "    #scrape_data()\n",
    "        \n",
    "# Pagination\n",
    "for page_number in range(1, 6):\n",
    "    scrape_data()\n",
    "    if page_number<5:\n",
    "        try:\n",
    "            # Locate the pagination container\n",
    "            pagination_container = wait.until(EC.presence_of_element_located(\n",
    "                (By.XPATH, '//*[@id=\"root\"]/div/div[4]/div[12]')\n",
    "            ))\n",
    "\n",
    "            # Locate the next page button within the container\n",
    "            next_page_button = pagination_container.find_element(\n",
    "                By.XPATH, f'.//div[contains(@class, \"DC_117_pageTabs\") and text()=\"{page_number + 1}\"]'\n",
    "            )\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(next_page_button).perform()\n",
    "            time.sleep(3)\n",
    "            #driver.execute_script(\"arguments[0].scrollIntoView();\", next_page_button)\n",
    "            #time.sleep(3)\n",
    "            next_page_button.click()\n",
    "            wait.until(EC.text_to_be_present_in_element((By.XPATH, '//div[contains(@class,\"DC_117_pageTabs DC_117_pageActive\")]'),str(page_number + 1)))\n",
    "            print('success')\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "    \n",
    "# print(\"Route Names:\", apsrtc_route_names)\n",
    "# print(\"Route Links:\", apsrtc_route_links)\n",
    "\n",
    "#creat dataframe\n",
    "# ap_df = pd.DataFrame({\"Route_Name\":apsrtc_route_names, \"Route Links\":apsrtc_route_links})\n",
    "# ap_df\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "apsrtc_data = []\n",
    "\n",
    "# Scraping loop\n",
    "for index in ap_df.index:\n",
    "    route = ap_df.loc[index].values[0]\n",
    "    url = ap_df.loc[index].values[1]\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//div[@class=\"button\" and text()= \"View Buses\"]'))\n",
    "            )\n",
    "            view_buses_button.click()\n",
    "            print('button clicked')\n",
    "        except TimeoutException:\n",
    "            print('Viewbutton notfound')\n",
    "        time.sleep(2)\n",
    "        #scrolling 25 times so that whole website loads\n",
    "        for t in range(25):\n",
    "            driver.execute_script(\"window.scrollBy(0, 650);\")\n",
    "        time.sleep(2)\n",
    "        print('scrolled down')\n",
    "\n",
    "        bus_list = WebDriverWait(driver, 30).until(\n",
    "                EC.presence_of_all_elements_located((By.XPATH, '//div[@class=\"clearfix bus-item\"]'))\n",
    "            )\n",
    "        bus_list = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, '//div[@class=\"clearfix bus-item\"]'))\n",
    "        )\n",
    "        for bus in bus_list:\n",
    "            try:\n",
    "                bus_name = bus.find_element(By.XPATH, './/div[@class=\"travels lh-24 f-bold d-color\"]').text\n",
    "            except:\n",
    "                bus_name = \"N/A\"\n",
    "            try:\n",
    "                bus_type = bus.find_element(By.XPATH, './/div[@class=\"bus-type f-12 m-top-16 l-color evBus\"]').text\n",
    "            except:\n",
    "                bus_type = \"N/A\"\n",
    "            try:\n",
    "                starting_time = bus.find_element(By.XPATH, './/div[@class=\"dp-time f-19 d-color f-bold\"]').text\n",
    "            except:\n",
    "                starting_time = \"N/A\"\n",
    "            try:\n",
    "                ending_time = bus.find_element(By.XPATH, './/div[@class=\"bp-time f-19 d-color disp-Inline\"]').text\n",
    "            except:\n",
    "                ending_time = \"N/A\"\n",
    "            try:\n",
    "                seat_avail = bus.find_element(By.XPATH, './/div[@class=\"column-eight w-15 fl\"]').text\n",
    "            except:\n",
    "                seat_avail = \"N/A\"\n",
    "            try:\n",
    "                fare = bus.find_element(By.XPATH, './/div[@class=\"fare d-block\"]').text\n",
    "            except:\n",
    "                fare = \"N/A\"\n",
    "            try:\n",
    "                rating = bus.find_element(By.XPATH, './/div[@class=\"rating-sec lh-24\"]').text\n",
    "            except:\n",
    "                rating = \"N/A\"\n",
    "            apsrtc_data.append([bus_name,route,url, bus_type, starting_time, ending_time, seat_avail, fare, rating])\n",
    "            \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping data from {url}: {str(e)}\")\n",
    "print(apsrtc_data)\n",
    "# Create a DataFrame\n",
    "# apdf = pd.DataFrame(apsrtc_data, columns=[\"Busname\", \"Route_Name\", \"Route Links\", \"Bustype\", \"departing_time\", \"reaching_time\", \"availability\", \"price\", \"star_rating\"])\n",
    "# apdf.to_csv('apbus1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb2c63b-4158-4946-b309-5587c67f1725",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Telangana bus details\n",
    "TS_route_names = []\n",
    "TS_route_links = []\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 20)\n",
    "driver.get('https://www.redbus.in/online-booking/rtc-directory')\n",
    "\n",
    "TS = driver.find_element(By.XPATH, '//a[@href=\"/online-booking/tsrtc\"]')\n",
    "TS.click()\n",
    "\n",
    "def scrape_data():\n",
    "    route_names = driver.find_elements(By.CLASS_NAME, \"route\")\n",
    "    for route_name in route_names:\n",
    "        TS_route_names.append(route_name.text)\n",
    "\n",
    "    route_links = driver.find_elements(By.CLASS_NAME, \"route\")\n",
    "    hrefs = [route_link.get_attribute('href') for route_link in route_links]\n",
    "    for href in hrefs:\n",
    "        TS_route_links.append(href)\n",
    "\n",
    "# Pagination\n",
    "for page_number in range(1, 4):\n",
    "    scrape_data()\n",
    "    if page_number<3:\n",
    "        try:\n",
    "            # Locate the pagination container\n",
    "            pagination_container = wait.until(EC.presence_of_element_located(\n",
    "                (By.XPATH, '//*[@id=\"root\"]/div/div[4]/div[12]')\n",
    "            ))\n",
    "\n",
    "            # Locate the next page button within the container\n",
    "            next_page_button = pagination_container.find_element(\n",
    "                By.XPATH, f'.//div[contains(@class, \"DC_117_pageTabs\") and text()=\"{page_number + 1}\"]'\n",
    "            )\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(next_page_button).perform()\n",
    "            time.sleep(3)\n",
    "            #driver.execute_script(\"arguments[0].scrollIntoView();\", next_page_button)\n",
    "            #time.sleep(3)\n",
    "            next_page_button.click()\n",
    "            wait.until(EC.text_to_be_present_in_element((By.XPATH, '//div[contains(@class,\"DC_117_pageTabs DC_117_pageActive\")]'),str(page_number + 1)))\n",
    "            print('success')\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "# TS_df = pd.DataFrame({\"Route_Name\":TS_route_names, \"Route Links\":TS_route_links})\n",
    "# TS_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44863ee7-f9fb-4e4e-913c-9750ba741e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Telangana-buses-details\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "tsrtc_data = []\n",
    "\n",
    "# Scraping loop\n",
    "for index in TS_df.index:\n",
    "    route = TS_df.loc[index].values[0]\n",
    "    url = TS_df.loc[index].values[1]\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//div[@class=\"button\" and text()= \"View Buses\"]'))\n",
    "            )\n",
    "            view_buses_button.click()\n",
    "            print('button clicked')\n",
    "        except TimeoutException:\n",
    "            print('Viewbutton notfound')\n",
    "        time.sleep(2)\n",
    "        #scrolling 25 times so that whole website loads\n",
    "        for t in range(25):\n",
    "            driver.execute_script(\"window.scrollBy(0, 650);\")\n",
    "        time.sleep(2)\n",
    "        print('scrolled down')\n",
    "\n",
    "        bus_list = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, '//div[@class=\"clearfix bus-item\"]'))\n",
    "        )\n",
    "        for bus in bus_list:\n",
    "            try:\n",
    "                bus_name = bus.find_element(By.XPATH, './/div[@class=\"travels lh-24 f-bold d-color\"]').text\n",
    "            except:\n",
    "                bus_name = \"N/A\"\n",
    "            try:\n",
    "                bus_type = bus.find_element(By.XPATH, './/div[@class=\"bus-type f-12 m-top-16 l-color evBus\"]').text\n",
    "            except:\n",
    "                bus_type = \"N/A\"\n",
    "            try:\n",
    "                starting_time = bus.find_element(By.XPATH, './/div[@class=\"dp-time f-19 d-color f-bold\"]').text\n",
    "            except:\n",
    "                starting_time = \"N/A\"\n",
    "            try:\n",
    "                ending_time = bus.find_element(By.XPATH, './/div[@class=\"bp-time f-19 d-color disp-Inline\"]').text\n",
    "            except:\n",
    "                ending_time = \"N/A\"\n",
    "            try:\n",
    "                seat_avail = bus.find_element(By.XPATH, './/div[@class=\"column-eight w-15 fl\"]').text\n",
    "            except:\n",
    "                seat_avail = \"N/A\"\n",
    "            try:\n",
    "                fare = bus.find_element(By.XPATH, './/div[@class=\"fare d-block\"]').text\n",
    "            except:\n",
    "                fare = \"N/A\"\n",
    "            try:\n",
    "                rating = bus.find_element(By.XPATH, './/div[@class=\"rating-sec lh-24\"]').text\n",
    "            except:\n",
    "                rating = \"N/A\"\n",
    "            tsrtc_data.append([bus_name,route,url, bus_type, starting_time, ending_time, seat_avail, fare, rating])\n",
    "            \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping data from {url}: {str(e)}\")\n",
    "print(tsrtc_data)\n",
    "# tsdf = pd.DataFrame(tsrtc_data, columns=[\"Busname\", \"Route_Name\", \"Route Links\", \"Bustype\", \"departing_time\", \"reaching_time\", \"availability\", \"price\", \"star_rating\"])\n",
    "# tsdf\n",
    "# to creat csv file\n",
    "# tsdf.to_csv('tsbus1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09120598-e11f-4ae1-a0e0-98ded0b44d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kerala bus details\n",
    "KL_route_names = []\n",
    "KL_route_links = []\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 20)\n",
    "driver.get('https://www.redbus.in/online-booking/rtc-directory')\n",
    "\n",
    "KL = driver.find_element(By.XPATH, '//a[@href=\"/online-booking/ksrtc-kerala\"]')\n",
    "KL.click()\n",
    "\n",
    "def scrape_data():\n",
    "    route_names = driver.find_elements(By.CLASS_NAME, \"route\")\n",
    "    for route_name in route_names:\n",
    "        KL_route_names.append(route_name.text)\n",
    "\n",
    "    route_links = driver.find_elements(By.CLASS_NAME, \"route\")\n",
    "    hrefs = [route_link.get_attribute('href') for route_link in route_links]\n",
    "    for href in hrefs:\n",
    "        KL_route_links.append(href)\n",
    "\n",
    "# Pagination\n",
    "for page_number in range(1, 3):\n",
    "    scrape_data()\n",
    "    if page_number<2:\n",
    "        try:\n",
    "            # Locate the pagination container\n",
    "            pagination_container = wait.until(EC.presence_of_element_located(\n",
    "                (By.XPATH, '//*[@id=\"root\"]/div/div[4]/div[12]')\n",
    "            ))\n",
    "\n",
    "            # Locate the next page button within the container\n",
    "            next_page_button = pagination_container.find_element(\n",
    "                By.XPATH, f'.//div[contains(@class, \"DC_117_pageTabs\") and text()=\"{page_number + 1}\"]'\n",
    "            )\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(next_page_button).perform()\n",
    "            time.sleep(3)\n",
    "            #driver.execute_script(\"arguments[0].scrollIntoView();\", next_page_button)\n",
    "            #time.sleep(3)\n",
    "            next_page_button.click()\n",
    "            wait.until(EC.text_to_be_present_in_element((By.XPATH, '//div[contains(@class,\"DC_117_pageTabs DC_117_pageActive\")]'),str(page_number + 1)))\n",
    "            print('success')\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "# KL_df = pd.DataFrame({\"Route_Name\":KL_route_names, \"Route Links\":KL_route_links})\n",
    "# KL_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be13b35-7b9d-4584-b12a-46acbe01f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kerala-buses-details\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "ksrtc_data = []\n",
    "\n",
    "# Scraping loop\n",
    "for index in KL_df.index:\n",
    "    route = KL_df.loc[index].values[0]\n",
    "    url = KL_df.loc[index].values[1]\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//div[@class=\"button\" and text()= \"View Buses\"]'))\n",
    "            )\n",
    "            view_buses_button.click()\n",
    "            print('button clicked')\n",
    "        except TimeoutException:\n",
    "            print('Viewbutton notfound')\n",
    "        time.sleep(2)\n",
    "        #scrolling 20 times so that whole website loads\n",
    "        for t in range(20):\n",
    "            driver.execute_script(\"window.scrollBy(0, 650);\")\n",
    "        time.sleep(2)\n",
    "        print('scrolled down')\n",
    "\n",
    "        bus_list = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, '//div[@class=\"clearfix bus-item\"]'))\n",
    "        )\n",
    "        for bus in bus_list:\n",
    "            try:\n",
    "                bus_name = bus.find_element(By.XPATH, './/div[@class=\"travels lh-24 f-bold d-color\"]').text\n",
    "            except:\n",
    "                bus_name = \"N/A\"\n",
    "            try:\n",
    "                bus_type = bus.find_element(By.XPATH, './/div[@class=\"bus-type f-12 m-top-16 l-color evBus\"]').text\n",
    "            except:\n",
    "                bus_type = \"N/A\"\n",
    "            try:\n",
    "                starting_time = bus.find_element(By.XPATH, './/div[@class=\"dp-time f-19 d-color f-bold\"]').text\n",
    "            except:\n",
    "                starting_time = \"N/A\"\n",
    "            try:\n",
    "                ending_time = bus.find_element(By.XPATH, './/div[@class=\"bp-time f-19 d-color disp-Inline\"]').text\n",
    "            except:\n",
    "                ending_time = \"N/A\"\n",
    "            try:\n",
    "                seat_avail = bus.find_element(By.XPATH, './/div[@class=\"column-eight w-15 fl\"]').text\n",
    "            except:\n",
    "                seat_avail = \"N/A\"\n",
    "            try:\n",
    "                fare = bus.find_element(By.XPATH, './/div[@class=\"fare d-block\"]').text\n",
    "            except:\n",
    "                fare = \"N/A\"\n",
    "            try:\n",
    "                rating = bus.find_element(By.XPATH, './/div[@class=\"rating-sec lh-24\"]').text\n",
    "            except:\n",
    "                rating = \"N/A\"\n",
    "            ksrtc_data.append([bus_name,route,url, bus_type, starting_time, ending_time, seat_avail, fare, rating])\n",
    "        print('done')    \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping data from {url}: {str(e)}\")\n",
    "print(ksrtc_data)\n",
    "# kldf = pd.DataFrame(ksrtc_data, columns=[\"Busname\", \"Route_Name\", \"Route Links\", \"Bustype\", \"departing_time\", \"reaching_time\", \"availability\", \"price\", \"star_rating\"])\n",
    "# kldf.to_csv('klbus1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa6134f-a478-4dc0-a634-ffb1853bd72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kadamba bus details\n",
    "KD_route_names = []\n",
    "KD_route_links = []\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 20)\n",
    "driver.get('https://www.redbus.in/online-booking/rtc-directory')\n",
    "\n",
    "KD = driver.find_element(By.XPATH, '//a[@href=\"/online-booking/ktcl\"]')\n",
    "KD.click()\n",
    "\n",
    "def scrape_data():\n",
    "    route_names = driver.find_elements(By.CLASS_NAME, \"route\")\n",
    "    for route_name in route_names:\n",
    "        KD_route_names.append(route_name.text)\n",
    "\n",
    "    route_links = driver.find_elements(By.CLASS_NAME, \"route\")\n",
    "    hrefs = [route_link.get_attribute('href') for route_link in route_links]\n",
    "    for href in hrefs:\n",
    "        KD_route_links.append(href)\n",
    "\n",
    "# Pagination\n",
    "for page_number in range(1, 5):\n",
    "    scrape_data()\n",
    "    if page_number<4:\n",
    "        try:\n",
    "            # Locate the pagination container\n",
    "            pagination_container = wait.until(EC.presence_of_element_located(\n",
    "                (By.XPATH, '//*[@id=\"root\"]/div/div[4]/div[12]')\n",
    "            ))\n",
    "\n",
    "            # Locate the next page button within the container\n",
    "            next_page_button = pagination_container.find_element(\n",
    "                By.XPATH, f'.//div[contains(@class, \"DC_117_pageTabs\") and text()=\"{page_number + 1}\"]'\n",
    "            )\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(next_page_button).perform()\n",
    "            time.sleep(3)\n",
    "            #driver.execute_script(\"arguments[0].scrollIntoView();\", next_page_button)\n",
    "            #time.sleep(3)\n",
    "            next_page_button.click()\n",
    "            wait.until(EC.text_to_be_present_in_element((By.XPATH, '//div[contains(@class,\"DC_117_pageTabs DC_117_pageActive\")]'),str(page_number + 1)))\n",
    "            print('success')\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "# KD_df = pd.DataFrame({\"Route_Name\":KD_route_names, \"Route Links\":KD_route_links})\n",
    "# KD_df\n",
    "\n",
    "#kadamba-buses-details\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "KTCL_data = []\n",
    "\n",
    "# Scraping loop\n",
    "for index in KD_df.index:\n",
    "    route = KD_df.loc[index].values[0]\n",
    "    url = KD_df.loc[index].values[1]\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//div[@class=\"button\" and text()= \"View Buses\"]'))\n",
    "            )\n",
    "            view_buses_button.click()\n",
    "            print('button clicked')\n",
    "        except TimeoutException:\n",
    "            print('Viewbutton notfound')\n",
    "        time.sleep(2)\n",
    "        #scrolling 25 times so that whole website loads\n",
    "        for t in range(25):\n",
    "            driver.execute_script(\"window.scrollBy(0, 650);\")\n",
    "        time.sleep(2)\n",
    "        print('scrolled down')\n",
    "\n",
    "        bus_list = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, '//div[@class=\"clearfix bus-item\"]'))\n",
    "        )\n",
    "        for bus in bus_list:\n",
    "            try:\n",
    "                bus_name = bus.find_element(By.XPATH, './/div[@class=\"travels lh-24 f-bold d-color\"]').text\n",
    "            except:\n",
    "                bus_name = \"N/A\"\n",
    "            try:\n",
    "                bus_type = bus.find_element(By.XPATH, './/div[@class=\"bus-type f-12 m-top-16 l-color evBus\"]').text\n",
    "            except:\n",
    "                bus_type = \"N/A\"\n",
    "            try:\n",
    "                starting_time = bus.find_element(By.XPATH, './/div[@class=\"dp-time f-19 d-color f-bold\"]').text\n",
    "            except:\n",
    "                starting_time = \"N/A\"\n",
    "            try:\n",
    "                ending_time = bus.find_element(By.XPATH, './/div[@class=\"bp-time f-19 d-color disp-Inline\"]').text\n",
    "            except:\n",
    "                ending_time = \"N/A\"\n",
    "            try:\n",
    "                seat_avail = bus.find_element(By.XPATH, './/div[@class=\"column-eight w-15 fl\"]').text\n",
    "            except:\n",
    "                seat_avail = \"N/A\"\n",
    "            try:\n",
    "                fare = bus.find_element(By.XPATH, './/div[@class=\"fare d-block\"]').text\n",
    "            except:\n",
    "                fare = \"N/A\"\n",
    "            try:\n",
    "                rating = bus.find_element(By.XPATH, './/div[@class=\"rating-sec lh-24\"]').text\n",
    "            except:\n",
    "                rating = \"N/A\"\n",
    "            KTCL_data.append([bus_name,route,url, bus_type, starting_time, ending_time, seat_avail, fare, rating])\n",
    "        print('done')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping data from {url}: {str(e)}\")\n",
    "print(KTCL_data)\n",
    "# ktcldf = pd.DataFrame(KTCL_data, columns=[\"Busname\", \"Route_Name\", \"Route Links\", \"Bustype\", \"departing_time\", \"reaching_time\", \"availability\", \"price\", \"star_rating\"])\n",
    "# ktcldf\n",
    "\n",
    "# ktcldf.to_csv('ktcbus1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5133a39-5f55-4e22-909d-12c57bfc9890",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rajasthan bus details\n",
    "RJ_route_names = []\n",
    "RJ_route_links = []\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 20)\n",
    "driver.get('https://www.redbus.in/online-booking/rtc-directory')\n",
    "\n",
    "RJ = driver.find_element(By.XPATH, '//a[@href=\"/online-booking/rsrtc\"]')\n",
    "RJ.click()\n",
    "\n",
    "def scrape_data():\n",
    "    route_names = driver.find_elements(By.CLASS_NAME, \"route\")\n",
    "    for route_name in route_names:\n",
    "        RJ_route_names.append(route_name.text)\n",
    "\n",
    "    route_links = driver.find_elements(By.CLASS_NAME, \"route\")\n",
    "    hrefs = [route_link.get_attribute('href') for route_link in route_links]\n",
    "    for href in hrefs:\n",
    "        RJ_route_links.append(href)\n",
    "\n",
    "# Pagination\n",
    "for page_number in range(1, 4):\n",
    "    scrape_data()\n",
    "    if page_number<3:\n",
    "        try:\n",
    "            # Locate the pagination container\n",
    "            pagination_container = wait.until(EC.presence_of_element_located(\n",
    "                (By.XPATH, '//*[@id=\"root\"]/div/div[4]/div[12]')\n",
    "            ))\n",
    "\n",
    "            # Locate the next page button within the container\n",
    "            next_page_button = pagination_container.find_element(\n",
    "                By.XPATH, f'.//div[contains(@class, \"DC_117_pageTabs\") and text()=\"{page_number + 1}\"]'\n",
    "            )\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(next_page_button).perform()\n",
    "            time.sleep(3)\n",
    "            #driver.execute_script(\"arguments[0].scrollIntoView();\", next_page_button)\n",
    "            #time.sleep(3)\n",
    "            next_page_button.click()\n",
    "            wait.until(EC.text_to_be_present_in_element((By.XPATH, '//div[contains(@class,\"DC_117_pageTabs DC_117_pageActive\")]'),str(page_number + 1)))\n",
    "            print('success')\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "# RJ_df = pd.DataFrame({\"Route_Name\":RJ_route_names, \"Route Links\":RJ_route_links})\n",
    "# RJ_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8235dcd4-8131-4952-bb8f-ea3c192466c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rajasthan\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "RSRTC_data = []\n",
    "\n",
    "# Scraping loop\n",
    "for index in RJ_df.index:\n",
    "    route = RJ_df.loc[index].values[0]\n",
    "    url = RJ_df.loc[index].values[1]\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//div[@class=\"button\" and text()= \"View Buses\"]'))\n",
    "            )\n",
    "            view_buses_button.click()\n",
    "            print('button clicked')\n",
    "        except TimeoutException:\n",
    "            print('Viewbutton notfound')\n",
    "        time.sleep(2)\n",
    "        #scrolling 25 times so that whole website loads\n",
    "        for t in range(25):\n",
    "            driver.execute_script(\"window.scrollBy(0, 650);\")\n",
    "        time.sleep(2)\n",
    "        print('scrolled down')\n",
    "\n",
    "        bus_list = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, '//div[@class=\"clearfix bus-item\"]'))\n",
    "        )\n",
    "        for bus in bus_list:\n",
    "            try:\n",
    "                bus_name = bus.find_element(By.XPATH, './/div[@class=\"travels lh-24 f-bold d-color\"]').text\n",
    "            except:\n",
    "                bus_name = \"N/A\"\n",
    "            try:\n",
    "                bus_type = bus.find_element(By.XPATH, './/div[@class=\"bus-type f-12 m-top-16 l-color evBus\"]').text\n",
    "            except:\n",
    "                bus_type = \"N/A\"\n",
    "            try:\n",
    "                starting_time = bus.find_element(By.XPATH, './/div[@class=\"dp-time f-19 d-color f-bold\"]').text\n",
    "            except:\n",
    "                starting_time = \"N/A\"\n",
    "            try:\n",
    "                ending_time = bus.find_element(By.XPATH, './/div[@class=\"bp-time f-19 d-color disp-Inline\"]').text\n",
    "            except:\n",
    "                ending_time = \"N/A\"\n",
    "            try:\n",
    "                seat_avail = bus.find_element(By.XPATH, './/div[@class=\"column-eight w-15 fl\"]').text\n",
    "            except:\n",
    "                seat_avail = \"N/A\"\n",
    "            try:\n",
    "                fare = bus.find_element(By.XPATH, './/div[@class=\"fare d-block\"]').text\n",
    "            except:\n",
    "                fare = \"N/A\"\n",
    "            try:\n",
    "                rating = bus.find_element(By.XPATH, './/div[@class=\"rating-sec lh-24\"]').text\n",
    "            except:\n",
    "                rating = \"N/A\"\n",
    "            RSRTC_data.append([bus_name,route,url, bus_type, starting_time, ending_time, seat_avail, fare, rating])\n",
    "        print('done')            \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping data from {url}: {str(e)}\")\n",
    "print(RSRTC_data)\n",
    "# rjdf = pd.DataFrame(RSRTC_data, columns=[\"Busname\", \"Route_Name\", \"Route Links\", \"Bustype\", \"departing_time\", \"reaching_time\", \"availability\", \"price\", \"star_rating\"])\n",
    "# rjdf\n",
    "\n",
    "# rjdf.to_csv('RJbus1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52cc28f-5f26-4e87-ab6f-9e1c82bded05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hariana bus details\n",
    "HR_route_names = []\n",
    "HR_route_links = []\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 20)\n",
    "driver.get('https://www.redbus.in/online-booking/rtc-directory')\n",
    "\n",
    "HR = driver.find_element(By.XPATH, '//a[@href=\"/online-booking/hrtc\"]')\n",
    "HR.click()\n",
    "\n",
    "def scrape_data():\n",
    "    route_names = driver.find_elements(By.CLASS_NAME, \"route\")\n",
    "    for route_name in route_names:\n",
    "        HR_route_names.append(route_name.text)\n",
    "\n",
    "    route_links = driver.find_elements(By.CLASS_NAME, \"route\")\n",
    "    hrefs = [route_link.get_attribute('href') for route_link in route_links]\n",
    "    for href in hrefs:\n",
    "        HR_route_links.append(href)\n",
    "\n",
    "# Pagination\n",
    "for page_number in range(1, 6):\n",
    "    scrape_data()\n",
    "    if page_number<5:\n",
    "        try:\n",
    "            # Locate the pagination container\n",
    "            pagination_container = wait.until(EC.presence_of_element_located(\n",
    "                (By.XPATH, '//*[@id=\"root\"]/div/div[4]/div[12]')\n",
    "            ))\n",
    "\n",
    "            # Locate the next page button within the container\n",
    "            next_page_button = pagination_container.find_element(\n",
    "                By.XPATH, f'.//div[contains(@class, \"DC_117_pageTabs\") and text()=\"{page_number + 1}\"]'\n",
    "            )\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(next_page_button).perform()\n",
    "            time.sleep(3)\n",
    "            #driver.execute_script(\"arguments[0].scrollIntoView();\", next_page_button)\n",
    "            #time.sleep(3)\n",
    "            next_page_button.click()\n",
    "            wait.until(EC.text_to_be_present_in_element((By.XPATH, '//div[contains(@class,\"DC_117_pageTabs DC_117_pageActive\")]'),str(page_number + 1)))\n",
    "            print('success')\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "# HR_df = pd.DataFrame({\"Route_Name\":HR_route_names, \"Route Links\":HR_route_links})\n",
    "# HR_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bc463a-8fb4-4920-b192-06e4346cc54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hariana\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "HRTC_data = []\n",
    "\n",
    "# Scraping loop\n",
    "for index in HR_df.index:\n",
    "    route = HR_df.loc[index].values[0]\n",
    "    url = HR_df.loc[index].values[1]\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//div[@class=\"button\" and text()= \"View Buses\"]'))\n",
    "            )\n",
    "            view_buses_button.click()\n",
    "            print('button clicked')\n",
    "        except TimeoutException:\n",
    "            print('Viewbutton notfound')\n",
    "        time.sleep(2)\n",
    "        #scrolling 25 times so that whole website loads\n",
    "        for t in range(25):\n",
    "            driver.execute_script(\"window.scrollBy(0, 650);\")\n",
    "        time.sleep(2)\n",
    "        print('scrolled down')\n",
    "\n",
    "        bus_list = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, '//div[@class=\"clearfix bus-item\"]'))\n",
    "        )\n",
    "        for bus in bus_list:\n",
    "            try:\n",
    "                bus_name = bus.find_element(By.XPATH, './/div[@class=\"travels lh-24 f-bold d-color\"]').text\n",
    "            except:\n",
    "                bus_name = \"N/A\"\n",
    "            try:\n",
    "                bus_type = bus.find_element(By.XPATH, './/div[@class=\"bus-type f-12 m-top-16 l-color evBus\"]').text\n",
    "            except:\n",
    "                bus_type = \"N/A\"\n",
    "            try:\n",
    "                starting_time = bus.find_element(By.XPATH, './/div[@class=\"dp-time f-19 d-color f-bold\"]').text\n",
    "            except:\n",
    "                starting_time = \"N/A\"\n",
    "            try:\n",
    "                ending_time = bus.find_element(By.XPATH, './/div[@class=\"bp-time f-19 d-color disp-Inline\"]').text\n",
    "            except:\n",
    "                ending_time = \"N/A\"\n",
    "            try:\n",
    "                seat_avail = bus.find_element(By.XPATH, './/div[@class=\"column-eight w-15 fl\"]').text\n",
    "            except:\n",
    "                seat_avail = \"N/A\"\n",
    "            try:\n",
    "                fare = bus.find_element(By.XPATH, './/div[@class=\"fare d-block\"]').text\n",
    "            except:\n",
    "                fare = \"N/A\"\n",
    "            try:\n",
    "                rating = bus.find_element(By.XPATH, './/div[@class=\"rating-sec lh-24\"]').text\n",
    "            except:\n",
    "                rating = \"N/A\"\n",
    "            HRTC_data.append([bus_name,route,url, bus_type, starting_time, ending_time, seat_avail, fare, rating])\n",
    "        print('done')\n",
    "            \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping data from {url}: {str(e)}\")\n",
    "print(HRTC_data)\n",
    "# hrdf = pd.DataFrame(HRTC_data, columns=[\"Busname\", \"Route_Name\", \"Route Links\", \"Bustype\", \"departing_time\", \"reaching_time\", \"availability\", \"price\", \"star_rating\"])\n",
    "# hrdf\n",
    "# hrdf.to_csv('HRbus1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfbbe8c-1dd2-4f08-b6cb-a6f449639f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UP bus details\n",
    "UP_route_names = []\n",
    "UP_route_links = []\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 20)\n",
    "driver.get('https://www.redbus.in/online-booking/uttar-pradesh-state-road-transport-corporation-upsrtc')\n",
    "\n",
    "# UP = driver.find_element(By.XPATH, '//a[@href=\"/online-booking/uttar-pradesh-state-road-transport-corporation-upsrtc\"]')\n",
    "# UP.click()\n",
    "\n",
    "def scrape_data():\n",
    "    route_names = driver.find_elements(By.CLASS_NAME, \"route\")\n",
    "    for route_name in route_names:\n",
    "        UP_route_names.append(route_name.text)\n",
    "\n",
    "    route_links = driver.find_elements(By.CLASS_NAME, \"route\")\n",
    "    hrefs = [route_link.get_attribute('href') for route_link in route_links]\n",
    "    for href in hrefs:\n",
    "        UP_route_links.append(href)\n",
    "\n",
    "# Pagination\n",
    "for page_number in range(1, 6):\n",
    "    scrape_data()\n",
    "    if page_number<5:\n",
    "        try:\n",
    "            # Locate the pagination container\n",
    "            pagination_container = wait.until(EC.presence_of_element_located(\n",
    "                (By.XPATH, '//*[@id=\"root\"]/div/div[4]/div[12]')\n",
    "            ))\n",
    "\n",
    "            # Locate the next page button within the container\n",
    "            next_page_button = pagination_container.find_element(\n",
    "                By.XPATH, f'.//div[contains(@class, \"DC_117_pageTabs\") and text()=\"{page_number + 1}\"]'\n",
    "            )\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(next_page_button).perform()\n",
    "            time.sleep(3)\n",
    "            #driver.execute_script(\"arguments[0].scrollIntoView();\", next_page_button)\n",
    "            #time.sleep(3)\n",
    "            next_page_button.click()\n",
    "            wait.until(EC.text_to_be_present_in_element((By.XPATH, '//div[contains(@class,\"DC_117_pageTabs DC_117_pageActive\")]'),str(page_number + 1)))\n",
    "            print('success')\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86c48cd-d4d2-4686-815d-1889d530e5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UP\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "UPSRTC_data = []\n",
    "\n",
    "# Scraping loop\n",
    "for index in UP_df.index:\n",
    "    route = UP_df.loc[index].values[0]\n",
    "    url = UP_df.loc[index].values[1]\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//div[@class=\"button\" and text()= \"View Buses\"]'))\n",
    "            )\n",
    "            view_buses_button.click()\n",
    "            print('button clicked')\n",
    "        except TimeoutException:\n",
    "            print('Viewbutton notfound')\n",
    "        time.sleep(2)\n",
    "        #scrolling 25 times so that whole website loads\n",
    "        for t in range(25):\n",
    "            driver.execute_script(\"window.scrollBy(0, 650);\")\n",
    "        time.sleep(2)\n",
    "        print('scrolled down')\n",
    "\n",
    "        bus_list = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, '//div[@class=\"clearfix bus-item\"]'))\n",
    "        )\n",
    "        for bus in bus_list:\n",
    "            try:\n",
    "                bus_name = bus.find_element(By.XPATH, './/div[@class=\"travels lh-24 f-bold d-color\"]').text\n",
    "            except:\n",
    "                bus_name = \"N/A\"\n",
    "            try:\n",
    "                bus_type = bus.find_element(By.XPATH, './/div[@class=\"bus-type f-12 m-top-16 l-color evBus\"]').text\n",
    "            except:\n",
    "                bus_type = \"N/A\"\n",
    "            try:\n",
    "                starting_time = bus.find_element(By.XPATH, './/div[@class=\"dp-time f-19 d-color f-bold\"]').text\n",
    "            except:\n",
    "                starting_time = \"N/A\"\n",
    "            try:\n",
    "                ending_time = bus.find_element(By.XPATH, './/div[@class=\"bp-time f-19 d-color disp-Inline\"]').text\n",
    "            except:\n",
    "                ending_time = \"N/A\"\n",
    "            try:\n",
    "                seat_avail = bus.find_element(By.XPATH, './/div[@class=\"column-eight w-15 fl\"]').text\n",
    "            except:\n",
    "                seat_avail = \"N/A\"\n",
    "            try:\n",
    "                fare = bus.find_element(By.XPATH, './/div[@class=\"fare d-block\"]').text\n",
    "            except:\n",
    "                fare = \"N/A\"\n",
    "            try:\n",
    "                rating = bus.find_element(By.XPATH, './/div[@class=\"rating-sec lh-24\"]').text\n",
    "            except:\n",
    "                rating = \"N/A\"\n",
    "            UPSRTC_data.append([bus_name,route,url, bus_type, starting_time, ending_time, seat_avail, fare, rating])\n",
    "        print('done')\n",
    "            \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping data from {url}: {str(e)}\")\n",
    "print(UPSRTC_data)\n",
    "# updf = pd.DataFrame(UPSRTC_data, columns=[\"Busname\", \"Route_Name\", \"Route Links\", \"Bustype\", \"departing_time\", \"reaching_time\", \"availability\", \"price\", \"star_rating\"])\n",
    "# updf\n",
    "# updf.to_csv('UPbus1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1ed80b-8a1b-48c3-a6b3-e954e8de49d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assam bus details\n",
    "AS_route_names = []\n",
    "AS_route_links = []\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 20)\n",
    "driver.get('https://www.redbus.in/online-booking/astc')\n",
    "\n",
    "# AS = driver.find_element(By.XPATH, '//a[@href=\"/online-booking/astc\"]')\n",
    "# AS.click()\n",
    "\n",
    "def scrape_data():\n",
    "    route_names = driver.find_elements(By.CLASS_NAME, \"route\")\n",
    "    for route_name in route_names:\n",
    "        AS_route_names.append(route_name.text)\n",
    "\n",
    "    route_links = driver.find_elements(By.CLASS_NAME, \"route\")\n",
    "    hrefs = [route_link.get_attribute('href') for route_link in route_links]\n",
    "    for href in hrefs:\n",
    "        AS_route_links.append(href)\n",
    "\n",
    "# Pagination\n",
    "for page_number in range(1, 6):\n",
    "    scrape_data()\n",
    "    if page_number<5:\n",
    "        try:\n",
    "            # Locate the pagination container\n",
    "            pagination_container = wait.until(EC.presence_of_element_located(\n",
    "                (By.XPATH, '//*[@id=\"root\"]/div/div[4]/div[12]')\n",
    "            ))\n",
    "\n",
    "            # Locate the next page button within the container\n",
    "            next_page_button = pagination_container.find_element(\n",
    "                By.XPATH, f'.//div[contains(@class, \"DC_117_pageTabs\") and text()=\"{page_number + 1}\"]'\n",
    "            )\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(next_page_button).perform()\n",
    "            time.sleep(3)\n",
    "            #driver.execute_script(\"arguments[0].scrollIntoView();\", next_page_button)\n",
    "            #time.sleep(3)\n",
    "            next_page_button.click()\n",
    "            wait.until(EC.text_to_be_present_in_element((By.XPATH, '//div[contains(@class,\"DC_117_pageTabs DC_117_pageActive\")]'),str(page_number + 1)))\n",
    "            print('success')\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "# AS_df = pd.DataFrame({\"Route_Name\":AS_route_names, \"Route Links\":AS_route_links})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87be3a7e-a93f-4c8a-b15d-a540541ae919",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assam\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "ASTC_data = []\n",
    "\n",
    "# Scraping loop\n",
    "for index in AS_df.index:\n",
    "    route = AS_df.loc[index].values[0]\n",
    "    url = AS_df.loc[index].values[1]\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//div[@class=\"button\" and text()= \"View Buses\"]'))\n",
    "            )\n",
    "            view_buses_button.click()\n",
    "            print('button clicked')\n",
    "        except TimeoutException:\n",
    "            print('Viewbutton notfound')\n",
    "        time.sleep(2)\n",
    "        #scrolling 25 times so that whole website loads\n",
    "        for t in range(20):\n",
    "            driver.execute_script(\"window.scrollBy(0, 650);\")\n",
    "        time.sleep(2)\n",
    "        print('scrolled down')\n",
    "\n",
    "        bus_list = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, '//div[@class=\"clearfix bus-item\"]'))\n",
    "        )\n",
    "        for bus in bus_list:\n",
    "            try:\n",
    "                bus_name = bus.find_element(By.XPATH, './/div[@class=\"travels lh-24 f-bold d-color\"]').text\n",
    "            except:\n",
    "                bus_name = \"N/A\"\n",
    "            try:\n",
    "                bus_type = bus.find_element(By.XPATH, './/div[@class=\"bus-type f-12 m-top-16 l-color evBus\"]').text\n",
    "            except:\n",
    "                bus_type = \"N/A\"\n",
    "            try:\n",
    "                starting_time = bus.find_element(By.XPATH, './/div[@class=\"dp-time f-19 d-color f-bold\"]').text\n",
    "            except:\n",
    "                starting_time = \"N/A\"\n",
    "            try:\n",
    "                ending_time = bus.find_element(By.XPATH, './/div[@class=\"bp-time f-19 d-color disp-Inline\"]').text\n",
    "            except:\n",
    "                ending_time = \"N/A\"\n",
    "            try:\n",
    "                seat_avail = bus.find_element(By.XPATH, './/div[@class=\"column-eight w-15 fl\"]').text\n",
    "            except:\n",
    "                seat_avail = \"N/A\"\n",
    "            try:\n",
    "                fare = bus.find_element(By.XPATH, './/div[@class=\"fare d-block\"]').text\n",
    "            except:\n",
    "                fare = \"N/A\"\n",
    "            try:\n",
    "                rating = bus.find_element(By.XPATH, './/div[@class=\"rating-sec lh-24\"]').text\n",
    "            except:\n",
    "                rating = \"N/A\"\n",
    "            ASTC_data.append([bus_name,route,url, bus_type, starting_time, ending_time, seat_avail, fare, rating])\n",
    "        print('done')\n",
    "            \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping data from {url}: {str(e)}\")\n",
    "print(ASTC_data)\n",
    "# asdf = pd.DataFrame(ASTC_data, columns=[\"Busname\", \"Route_Name\", \"Route Links\", \"Bustype\", \"departing_time\", \"reaching_time\", \"availability\", \"price\", \"star_rating\"])\n",
    "# asdf\n",
    "# asdf.to_csv('assambus1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534da761-259c-40d4-89f0-7b14087d0080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sikim bus details\n",
    "SK_route_names = []\n",
    "SK_route_links = []\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 20)\n",
    "driver.get('https://www.redbus.in/online-booking/sikkim-nationalised-transport-snt')\n",
    "\n",
    "# SK = driver.find_element(By.XPATH, '//a[@href=\"/online-booking/sikkim-nationalised-transport-snt\"]')\n",
    "# SK.click()\n",
    "\n",
    "def scrape_data():\n",
    "    route_names = driver.find_elements(By.CLASS_NAME, \"route\")\n",
    "    for route_name in route_names:\n",
    "        SK_route_names.append(route_name.text)\n",
    "\n",
    "    route_links = driver.find_elements(By.CLASS_NAME, \"route\")\n",
    "    hrefs = [route_link.get_attribute('href') for route_link in route_links]\n",
    "    for href in hrefs:\n",
    "        SK_route_links.append(href)\n",
    "\n",
    "# Pagination\n",
    "for page_number in range(1, 3):\n",
    "    scrape_data()\n",
    "    if page_number<2:\n",
    "        try:\n",
    "            # Locate the pagination container\n",
    "            pagination_container = wait.until(EC.presence_of_element_located(\n",
    "                (By.XPATH, '//*[@id=\"root\"]/div/div[4]/div[12]')\n",
    "            ))\n",
    "\n",
    "            # Locate the next page button within the container\n",
    "            next_page_button = pagination_container.find_element(\n",
    "                By.XPATH, f'.//div[contains(@class, \"DC_117_pageTabs\") and text()=\"{page_number + 1}\"]'\n",
    "            )\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(next_page_button).perform()\n",
    "            time.sleep(3)\n",
    "            #driver.execute_script(\"arguments[0].scrollIntoView();\", next_page_button)\n",
    "            #time.sleep(3)\n",
    "            next_page_button.click()\n",
    "            wait.until(EC.text_to_be_present_in_element((By.XPATH, '//div[contains(@class,\"DC_117_pageTabs DC_117_pageActive\")]'),str(page_number + 1)))\n",
    "            print('success')\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "SK_df = pd.DataFrame({\"Route_Name\":SK_route_names, \"Route Links\":SK_route_links})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d68c7d6-0d5b-4661-8b59-c35872e9ad49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sikim\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "SNT_data = []\n",
    "\n",
    "# Scraping loop\n",
    "for index in SK_df.index:\n",
    "    route = SK_df.loc[index].values[0]\n",
    "    url = SK_df.loc[index].values[1]\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//div[@class=\"button\" and text()= \"View Buses\"]'))\n",
    "            )\n",
    "            view_buses_button.click()\n",
    "            print('button clicked')\n",
    "        except TimeoutException:\n",
    "            print('Viewbutton notfound')\n",
    "        time.sleep(2)\n",
    "        #scrolling 25 times so that whole website loads\n",
    "        for t in range(25):\n",
    "            driver.execute_script(\"window.scrollBy(0, 650);\")\n",
    "        time.sleep(2)\n",
    "        print('scrolled down')\n",
    "\n",
    "        bus_list = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, '//div[@class=\"clearfix bus-item\"]'))\n",
    "        )\n",
    "        for bus in bus_list:\n",
    "            try:\n",
    "                bus_name = bus.find_element(By.XPATH, './/div[@class=\"travels lh-24 f-bold d-color\"]').text\n",
    "            except:\n",
    "                bus_name = \"N/A\"\n",
    "            try:\n",
    "                bus_type = bus.find_element(By.XPATH, './/div[@class=\"bus-type f-12 m-top-16 l-color evBus\"]').text\n",
    "            except:\n",
    "                bus_type = \"N/A\"\n",
    "            try:\n",
    "                starting_time = bus.find_element(By.XPATH, './/div[@class=\"dp-time f-19 d-color f-bold\"]').text\n",
    "            except:\n",
    "                starting_time = \"N/A\"\n",
    "            try:\n",
    "                ending_time = bus.find_element(By.XPATH, './/div[@class=\"bp-time f-19 d-color disp-Inline\"]').text\n",
    "            except:\n",
    "                ending_time = \"N/A\"\n",
    "            try:\n",
    "                seat_avail = bus.find_element(By.XPATH, './/div[@class=\"column-eight w-15 fl\"]').text\n",
    "            except:\n",
    "                seat_avail = \"N/A\"\n",
    "            try:\n",
    "                fare = bus.find_element(By.XPATH, './/div[@class=\"fare d-block\"]').text\n",
    "            except:\n",
    "                fare = \"N/A\"\n",
    "            try:\n",
    "                rating = bus.find_element(By.XPATH, './/div[@class=\"rating-sec lh-24\"]').text\n",
    "            except:\n",
    "                rating = \"N/A\"\n",
    "            SNT_data.append([bus_name,route,url, bus_type, starting_time, ending_time, seat_avail, fare, rating])\n",
    "        print('done')\n",
    "            \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping data from {url}: {str(e)}\")\n",
    "print(SNT_data)\n",
    "# skdf = pd.DataFrame(SNT_data, columns=[\"Busname\", \"Route_Name\", \"Route Links\", \"Bustype\", \"departing_time\", \"reaching_time\", \"availability\", \"price\", \"star_rating\"])\n",
    "# skdf\n",
    "# skdf.to_csv('sikkimbus1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c415776-1574-4db2-a255-a4147400d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WB bus details\n",
    "WB_route_names = []\n",
    "WB_route_links = []\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 20)\n",
    "driver.get('https://www.redbus.in/online-booking/west-bengal-transport-corporation')\n",
    "\n",
    "# WB = driver.find_element(By.XPATH, '//a[@href=\"/online-booking/west-bengal-transport-corporation\"]')\n",
    "# WB.click()\n",
    "\n",
    "def scrape_data():\n",
    "    route_names = driver.find_elements(By.CLASS_NAME, \"route\")\n",
    "    for route_name in route_names:\n",
    "        WB_route_names.append(route_name.text)\n",
    "\n",
    "    route_links = driver.find_elements(By.CLASS_NAME, \"route\")\n",
    "    hrefs = [route_link.get_attribute('href') for route_link in route_links]\n",
    "    for href in hrefs:\n",
    "        WB_route_links.append(href)\n",
    "scrape_data()\n",
    "WB_df = pd.DataFrame({\"Route_Name\":WB_route_names, \"Route Links\":WB_route_links})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a834edc-aaf9-4a5c-975e-b8b58b739a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#West bengal\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "WB_data = []\n",
    "\n",
    "# Scraping loop\n",
    "for index in WB_df.index:\n",
    "    route = WB_df.loc[index].values[0]\n",
    "    url = WB_df.loc[index].values[1]\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//div[@class=\"button\" and text()= \"View Buses\"]'))\n",
    "            )\n",
    "            view_buses_button.click()\n",
    "            print('button clicked')\n",
    "        except TimeoutException:\n",
    "            print('Viewbutton notfound')\n",
    "        time.sleep(2)\n",
    "        #scrolling 25 times so that whole website loads\n",
    "        for t in range(25):\n",
    "            driver.execute_script(\"window.scrollBy(0, 650);\")\n",
    "        time.sleep(2)\n",
    "        print('scrolled down')\n",
    "\n",
    "        bus_list = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, '//div[@class=\"clearfix bus-item\"]'))\n",
    "        )\n",
    "        for bus in bus_list:\n",
    "            try:\n",
    "                bus_name = bus.find_element(By.XPATH, './/div[@class=\"travels lh-24 f-bold d-color\"]').text\n",
    "            except:\n",
    "                bus_name = \"N/A\"\n",
    "            try:\n",
    "                bus_type = bus.find_element(By.XPATH, './/div[@class=\"bus-type f-12 m-top-16 l-color evBus\"]').text\n",
    "            except:\n",
    "                bus_type = \"N/A\"\n",
    "            try:\n",
    "                starting_time = bus.find_element(By.XPATH, './/div[@class=\"dp-time f-19 d-color f-bold\"]').text\n",
    "            except:\n",
    "                starting_time = \"N/A\"\n",
    "            try:\n",
    "                ending_time = bus.find_element(By.XPATH, './/div[@class=\"bp-time f-19 d-color disp-Inline\"]').text\n",
    "            except:\n",
    "                ending_time = \"N/A\"\n",
    "            try:\n",
    "                seat_avail = bus.find_element(By.XPATH, './/div[@class=\"column-eight w-15 fl\"]').text\n",
    "            except:\n",
    "                seat_avail = \"N/A\"\n",
    "            try:\n",
    "                fare = bus.find_element(By.XPATH, './/div[@class=\"fare d-block\"]').text\n",
    "            except:\n",
    "                fare = \"N/A\"\n",
    "            try:\n",
    "                rating = bus.find_element(By.XPATH, './/div[@class=\"rating-sec lh-24\"]').text\n",
    "            except:\n",
    "                rating = \"N/A\"\n",
    "            WB_data.append([bus_name,route,url, bus_type, starting_time, ending_time, seat_avail, fare, rating])\n",
    "        print('done')\n",
    "            \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping data from {url}: {str(e)}\")\n",
    "print(WB_data)\n",
    "# wbdf = pd.DataFrame(WB_data, columns=[\"Busname\", \"Route_Name\", \"Route Links\", \"Bustype\", \"departing_time\", \"reaching_time\", \"availability\", \"price\", \"star_rating\"])\n",
    "# wbdf\n",
    "# wbdf.to_csv('wbbus1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ff2ce9-a407-4fce-85e8-e3a8bb74ad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "redbus_finel = pd.concat(map(pd.read_csv, ['apbus1.csv', 'tsbus1.csv', 'klbus1.csv', 'ktcbus1.csv', 'RJbus1.csv', 'HRbus1.csv',\n",
    "                                           'UPbus1.csv', 'assambus1.csv', 'sikkimbus1.csv', 'wbbus1.csv',]), ignore_index=True)\n",
    "redbus_finel.to_csv('redbusfinal1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee146f94-3c0d-4a1b-a573-db26d9682162",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = mysql.connector.connect(\n",
    "host=\"localhost\",\n",
    "user=\"root\",\n",
    "password=\"Ragavan@96\"\n",
    ")\n",
    "cursor = con.cursor()\n",
    "query = \"create database if not exists REDBUS_PROJECT\"\n",
    "cursor.execute(query)\n",
    "query = \"use REDBUS_PROJECT\"\n",
    "cursor.execute(query)\n",
    "query = \"\"\"CREATE TABLE IF NOT EXISTS Allbus3 (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY, \n",
    "    Busname VARCHAR(100), \n",
    "    Route_Name VARCHAR(100), \n",
    "    Route_Links VARCHAR(180), \n",
    "    Bustype VARCHAR(80), \n",
    "    departing_time TIME,\n",
    "    reaching_time TIME, \n",
    "    seats_available VARCHAR(180), \n",
    "    price FLOAT(7, 2), \n",
    "    star_rating DECIMAL(2,1)\n",
    ")\"\"\"\n",
    "cursor.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb12dfa-93a6-4715-aead-858fb1a5f05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to clean the price column\n",
    "def clean_price(price_str):\n",
    "    # Use a regular expression to extract the numeric part of the price\n",
    "    return float(re.sub(r'[^\\d.]', '', str(price_str)))\n",
    "\n",
    "# Apply the cleaning function to the price column\n",
    "df['price'] = df['price'].apply(clean_price)\n",
    "df['star_rating'] = df['star_rating'].astype(float)  # Ensure star_rating is a float\n",
    "\n",
    "# Updated data insertion code\n",
    "query = \"\"\"INSERT INTO Allbus3 (Busname, Route_Name, Route_Links, Bustype, departing_time, reaching_time, seats_available, price, star_rating) \n",
    "           VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\"\"\"\n",
    "\n",
    "df_list = df.values.tolist()\n",
    "for row in df_list:\n",
    "    cursor.execute(query,row)\n",
    "con.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
